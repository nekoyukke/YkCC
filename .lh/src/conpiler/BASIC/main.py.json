{
    "sourceFile": "src/conpiler/BASIC/main.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 3,
            "patches": [
                {
                    "date": 1760705360196,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1760705389519,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,8 +11,9 @@\n \r\n lex = lexer.Lexer()\r\n toks = lex.tokenize(\"10 FOR I = 0 TO 10\\n\" \\\r\n                     \"20 FOR J = 0 TO 10\\n\" \\\r\n-                    \"30 NEXT\\n\" \\\r\n-                    \"40 NEXT\\n\")\r\n+                    \"30 \"\r\n+                    \"40 NEXT\\n\" \\\r\n+                    \"50 NEXT\\n\")\r\n print(toks)\r\n print(parse.parse(\"\", toks))\n\\ No newline at end of file\n"
                },
                {
                    "date": 1760706111483,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,9 +11,9 @@\n \r\n lex = lexer.Lexer()\r\n toks = lex.tokenize(\"10 FOR I = 0 TO 10\\n\" \\\r\n                     \"20 FOR J = 0 TO 10\\n\" \\\r\n-                    \"30 \"\r\n+                    \"30 PRINT \"\r\n                     \"40 NEXT\\n\" \\\r\n                     \"50 NEXT\\n\")\r\n print(toks)\r\n print(parse.parse(\"\", toks))\n\\ No newline at end of file\n"
                },
                {
                    "date": 1760706169522,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,9 +11,9 @@\n \r\n lex = lexer.Lexer()\r\n toks = lex.tokenize(\"10 FOR I = 0 TO 10\\n\" \\\r\n                     \"20 FOR J = 0 TO 10\\n\" \\\r\n-                    \"30 PRINT \"\r\n+                    \"30 PRINT I J\\n\"\r\n                     \"40 NEXT\\n\" \\\r\n                     \"50 NEXT\\n\")\r\n print(toks)\r\n print(parse.parse(\"\", toks))\n\\ No newline at end of file\n"
                }
            ],
            "date": 1760705360196,
            "name": "Commit-0",
            "content": "from __future__ import annotations\r\nimport sys\r\nfrom pathlib import Path\r\nimport parse\r\nimport lexer\r\n\r\n\"\"\"repo_root = Path(__file__).resolve().parents[2]\r\nif str(repo_root) not in sys.path:\r\n    sys.path.insert(0, str(repo_root))\r\nimport src.util as util\"\"\"\r\n\r\nlex = lexer.Lexer()\r\ntoks = lex.tokenize(\"10 FOR I = 0 TO 10\\n\" \\\r\n                    \"20 FOR J = 0 TO 10\\n\" \\\r\n                    \"30 NEXT\\n\" \\\r\n                    \"40 NEXT\\n\")\r\nprint(toks)\r\nprint(parse.parse(\"\", toks))"
        }
    ]
}